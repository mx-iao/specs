reference:
  - title: Workspace
    desc: >
      Functions for manipulating workspace resources. A <b>Workspace</b> is the top-level resource for Azure Machine Learning service. 
      It provides a centralized place to work with all the artifacts you create when you use Azure ML.
    contents:
      - create_workspace
      - get_workspace
      - load_workspace_from_config
      - write_workspace_config
      - list_workspaces
      - get_default_datastore
      - delete_workspace
  - title: Compute target
    desc: > 
      Functions for manipulating compute resources. A <b>ComputeTarget</b> is a designated compute resource where you run your scripts 
      or host your service deployments. Compute targets make it easy to change your compute environment without changing your code.
      Supported compute target types in the R SDK include <b>AmlCompute</b> and <b>AksCompute</b>.
    contents:
      - get_compute
      - wait_for_compute
      - delete_compute
      - create_aml_compute
      - create_aks_compute
      - get_aks_compute_credentials
      - attach_aks_compute
      - detach_aks_compute
  - title: Datastore
    desc: >  
      Functions for managing datastores. A <b>Datastore</b> is attached to a workspace and is used to store 
      connection information to an Azure storage service. The following Azure storage services can be registered as datastores through 
      the R SDK: Azure Blob Container and Azure File Share.
    contents:
      - get_datastore
      - upload_files_to_datastore
      - upload_to_datastore
      - download_from_datastore
      - set_as_default_datastore
      - register_azure_blob_container_datastore
      - register_azure_file_share_datastore
      - unregister_datastore
  - title: Experiment and Run
    desc: >  
      Functions for managing experiments and runs. An <b>Experiment</b> is a grouping of the collection of runs from a specified script. 
      A <b>Run</b> represents a single trial of an experiment. A run is the object used to monitor the asynchronous execution of a trial, 
      log metrics and store output of the trial, and to analyze results and access artifacts generated by the trial. The following run 
      types are supported: ScriptRun (for Estimator experiments), HyperDriveRun (for HyperDrive experiments), and PipelineRun 
      (for Pipeline experiments). For functions that are specific only to HyperDriveRuns and PipelineRuns, see the respective HyperDrive 
      and Pipeline reference sections.
    content:
      - experiment
      - submit_experiment
      - get_run
      - wait_for_run_completion
      - get_current_run
      - log_metric_to_run
      - get_run_metrics
      - cancel_run
  - title: Estimator
    desc: >
      Functions for managing an estimator. An <b>Estimator</b> wraps run configuration information for specifying details of executing 
      an R script. Running an Estimator experiment (using the submit_experiment method) will return a ScriptRun object and execute your 
      training script on the specified compute target.
    content:
      - estimator
  - title: HyperDrive
    desc: > 
      Functions for configuring and managing hyperparameter tuning experiments. Azure ML's HyperDrive functionality enables you to 
      automate hyperparameter tuning of your machine learning models. For example, you can define the parameter search space as 
      discrete or continuous, and a sampling method over the search space as random, grid, or Bayesian. Also, you can specify a 
      primary metric to optimize in the hyperparameter tuning experiment, and whether to minimize or maximize that metric. You 
      can also define early termination policies in which poorly performing experiment runs are canceled and new ones started.
    content:
      - hyperdrive_config
      - random_parameter_sampling
      - grid_parameter_sampling
      - bayesian_parameter_sampling
      - randint
      - uniform
      - quniform
      - loguniform
      - qloguniform
      - normal
      - qnormal
      - lognormal
      - qlognormal
      - primary_metric_goal
      - bandit_policy
      - median_stopping_policy
      - truncation_selection_policy
      - get_best_run_by_primary_metric
      - get_child_runs_sorted_by_primary_metric
      - get_child_run_hyperparameters
      - get_child_run_metrics
  - title: Model
    desc: > 
      Functions for model management and deployment configurations. Registering a model allows you to store and version your trained 
      model in a workspace. A registered <b>Model</b> can then be deployed using Azure ML. To deploy a model, you will need to specify 
      the model deployment configuration via the <b>InferenceConfig</b>. If you would like to access all the assets needed to host a 
      model as a webservice without actually deploying the model, you can do so by packaging the model as a <b>ModelPackage</b>.
    content: 
      - get_model
      - register_model
      - download_model
      - deploy_model
      - package_model
      - delete_model
      - ModelPackage methods
      - InferenceConfig methods
      - Environment methods
  - title: Webservice
    desc: >
    content:
  - title: Pipeline
    desc: >
    content:
